# ğŸ—ï¸ Architecture Documentation

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     1C PORTAL RAG CHATBOT                        â”‚
â”‚                    Complete System Architecture                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      OFFLINE PHASE (One-Time)                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    ğŸ“„ PDF Document
    (1C_Portal_Support_Guide_v3.2.pdf)
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   PyPDF2 Parser   â”‚ â”€â”€â”€â–º Extract text page by page
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Text Chunking    â”‚ â”€â”€â”€â–º Split into 500-char pieces
    â”‚  (500 chars with  â”‚      with 100-char overlap
    â”‚   100 overlap)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ OpenAI Embedding  â”‚ â”€â”€â”€â–º text-embedding-ada-002
    â”‚   API Call        â”‚      Converts to 1536D vectors
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  FAISS Index      â”‚ â”€â”€â”€â–º Store vectors for fast search
    â”‚  (IndexFlatIP)    â”‚      Inner Product similarity
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    ğŸ’¾ Save to Disk
    â”œâ”€ vectors.index (FAISS binary)
    â””â”€ chunks.pkl (Text + metadata)


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ONLINE PHASE (Every Query)                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    ğŸ‘¤ User Question
    "How do I fill timesheet?"
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Query Embedding   â”‚ â”€â”€â”€â–º Convert to 1536D vector
    â”‚   (OpenAI API)    â”‚      Same model as documents
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Vector Search     â”‚ â”€â”€â”€â–º FAISS similarity search
    â”‚  (Top-K = 5)      â”‚      Find 5 most similar chunks
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Retrieve Chunks   â”‚ â”€â”€â”€â–º Get text from matched vectors
    â”‚ + Page Numbers    â”‚      Include source metadata
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Build Context    â”‚ â”€â”€â”€â–º Combine chunks into prompt
    â”‚  (RAG Prompt)     â”‚      System + Context + Query
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   GPT-3.5 Turbo   â”‚ â”€â”€â”€â–º Generate answer using context
    â”‚  Answer Generationâ”‚      Cites page numbers
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
    ğŸ¤– Answer + Sources
    "To fill timesheet: 1. Navigate to... (Page 8, 9)"
```

---

## Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA TRANSFORMATION                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT (PDF)
â”‚
â”œâ”€ Page 1: "Timesheet Management..."  (2,500 chars)
â”œâ”€ Page 2: "Leave Application..."     (2,800 chars)  
â””â”€ Page 3: "Expense Claims..."        (2,300 chars)
         â”‚
         â–¼ CHUNKING
         â”‚
â”œâ”€ Chunk 1: "Timesheet Management. To submit..." [500 chars]
â”œâ”€ Chunk 2: "...submit timesheet, navigate..."  [500 chars]
â”œâ”€ Chunk 3: "...navigate to portal home..."     [500 chars]
â””â”€ ...
         â”‚
         â–¼ EMBEDDING (OpenAI)
         â”‚
â”œâ”€ Vector 1: [0.023, -0.145, 0.892, ..., 0.334] (1536 dims)
â”œâ”€ Vector 2: [0.156, -0.023, 0.445, ..., 0.891] (1536 dims)
â”œâ”€ Vector 3: [0.234, 0.567, -0.123, ..., 0.678] (1536 dims)
â””â”€ ...
         â”‚
         â–¼ FAISS INDEX
         â”‚
    [Searchable Vector Database]
         â”‚
         â–¼ QUERY TIME
         â”‚
User Query: "timesheet submission"
         â”‚
Query Vector: [0.045, -0.123, 0.778, ..., 0.456]
         â”‚
         â–¼ SIMILARITY SEARCH
         â”‚
Cosine Similarity Calculation:
- Chunk 1: 0.89 âœ“ (High match!)
- Chunk 2: 0.85 âœ“
- Chunk 5: 0.12 âœ— (Low match)
         â”‚
         â–¼ TOP-K SELECTION
         â”‚
Top 5 Most Relevant Chunks
         â”‚
         â–¼ GPT GENERATION
         â”‚
Answer: "To submit timesheet, navigate to..."
```

---

## Component Interaction

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SYSTEM COMPONENTS                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   config.py â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚pdf_to_vectorsâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚Vector DB â”‚
â”‚  (Settings) â”‚         â”‚     .py      â”‚         â”‚  Storage â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚                       â”‚
                               â”‚ creates               â”‚
                               â–¼                       â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ chunks.pkl   â”‚       â”‚vectors.indexâ”‚
                        â”‚ (Text data)  â”‚       â”‚(FAISS index)â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚                       â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚ loaded by
                                       â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚ ask_questions.pyâ”‚
                              â”‚  (Query Logic)  â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â”‚ used by
                                       â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  rag_chatbot.py â”‚
                              â”‚   (Main App)    â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â”‚ interacts with
                                       â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚  User   â”‚
                                  â”‚ (You!)  â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## File Size & Storage

```
ğŸ“Š STORAGE BREAKDOWN
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Input:
â”œâ”€ PDF Document:        2.5 MB
â””â”€ Total Pages:         20

After Processing:
â”œâ”€ Text Chunks:         ~250 chunks
â”œâ”€ chunks.pkl:          150 KB (text + metadata)
â””â”€ vectors.index:       1.5 MB (FAISS index)

Total Vector DB Size:   ~1.65 MB

Memory Usage (Runtime):
â”œâ”€ FAISS Index:         ~2 MB in RAM
â”œâ”€ Text Chunks:         ~200 KB in RAM
â””â”€ Python Process:      ~50 MB total
```

---

## Query Performance

```
â±ï¸  TIMING BREAKDOWN (Average Query)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Step 1: Load Database          0.1s  â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
Step 2: Embed Query            0.5s  â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘
Step 3: FAISS Search           0.001s â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
Step 4: Retrieve Chunks        0.01s â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
Step 5: GPT Generation         1.5s  â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“

Total Query Time:              ~2.1 seconds
                              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                              85% is OpenAI API
                              15% is local processing
```

---

## Similarity Search Example

```
ğŸ” HOW SIMILARITY SEARCH WORKS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Query: "How to reset password?"
Query Vector: [0.23, -0.45, 0.78, ..., 0.12]

Document Chunks in Vector Space:

                    ğŸ“„ "Password reset process..."
                    Score: 0.92 âœ“ (Very Similar!)
                         â”‚
                         â”‚    ğŸ“„ "Account security..."
                         â”‚    Score: 0.75 âœ“
    ğŸ“„ "Timesheet..."    â”‚         â”‚
    Score: 0.23         â“Query    â”‚
                         â”‚         â”‚
                         â”‚    ğŸ“„ "Leave policy..."
                    ğŸ“„ "Project..."   Score: 0.15
                    Score: 0.18


Cosine Similarity Formula:
similarity = dot(vec1, vec2) / (|vec1| * |vec2|)

Range: [-1, 1]
  1.0  = Identical
  0.0  = Unrelated
 -1.0  = Opposite

Threshold: 0.5 (only return chunks > 0.5)
```

---

## Code Execution Flow

```python
# INDEXING FLOW (pdf_to_vectors.py)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    pdf = open("data/document.pdf")           # 1. Load PDF
    â†“
    pages = extract_text(pdf)                 # 2. Extract text
    â†“
    chunks = create_chunks(pages)             # 3. Split into chunks
    â†“
    embeddings = get_embeddings(chunks)       # 4. Call OpenAI API
    â†“
    index = build_faiss_index(embeddings)     # 5. Create FAISS index
    â†“
    save(index, chunks)                       # 6. Save to disk


# QUERY FLOW (rag_chatbot.py)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def query(question):
    index, chunks = load_database()           # 1. Load from disk
    â†“
    query_vec = embed_query(question)         # 2. Embed question
    â†“
    indices = index.search(query_vec, k=5)    # 3. Find top-5
    â†“
    context = get_chunks(indices)             # 4. Get text
    â†“
    prompt = build_prompt(question, context)  # 5. Build prompt
    â†“
    answer = call_gpt(prompt)                 # 6. Generate answer
    â†“
    return answer
```

---

## API Calls & Costs

```
ğŸ’° COST BREAKDOWN
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

INDEXING (One-time):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Text Chunks: 250                       â”‚
â”‚ Embedding Model: text-embedding-ada-002â”‚
â”‚ Cost: $0.0001 per 1K tokens           â”‚
â”‚                                        â”‚
â”‚ Calculation:                           â”‚
â”‚ 250 chunks Ã— 100 tokens = 25K tokens  â”‚
â”‚ 25K tokens Ã— $0.0001/1K = $0.0025     â”‚
â”‚                                        â”‚
â”‚ TOTAL INDEXING COST: ~$0.50 - $1.00   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PER QUERY:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Query Embedding                     â”‚
â”‚    ~20 tokens Ã— $0.0001/1K = $0.000002â”‚
â”‚                                        â”‚
â”‚ 2. GPT Generation                      â”‚
â”‚    Prompt: 2000 tokens                 â”‚
â”‚    Response: 500 tokens                â”‚
â”‚    Cost: $0.002/1K tokens              â”‚
â”‚    2500 Ã— $0.002/1K = $0.005          â”‚
â”‚                                        â”‚
â”‚ TOTAL PER QUERY: ~$0.01 - $0.03       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

100 QUERIES: ~$1 - $3
1000 QUERIES: ~$10 - $30
```

---

## Technology Stack

```
ğŸ› ï¸  TECH STACK
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Layer         â”‚   Technology         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Language        â”‚ Python 3.8+          â”‚
â”‚ PDF Parser      â”‚ PyPDF2               â”‚
â”‚ Embeddings      â”‚ OpenAI Ada-002       â”‚
â”‚ Vector DB       â”‚ FAISS                â”‚
â”‚ LLM             â”‚ GPT-3.5-turbo        â”‚
â”‚ Arrays          â”‚ NumPy                â”‚
â”‚ Serialization   â”‚ Pickle               â”‚
â”‚ IDE             â”‚ PyCharm              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ALTERNATIVES:
â”œâ”€ Embeddings:  Sentence-BERT, Cohere
â”œâ”€ Vector DB:   Pinecone, Weaviate, Milvus
â”œâ”€ LLM:         Claude, Llama, Mistral
â””â”€ PDF Parser:  PyMuPDF, pdfplumber
```

---

## Scalability Considerations

```
ğŸ“ˆ SCALING THE SYSTEM
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Current Setup (Small Scale):
â”œâ”€ Documents:     1 PDF (20 pages)
â”œâ”€ Chunks:        ~250
â”œâ”€ Index Type:    IndexFlatIP (exact search)
â”œâ”€ Query Time:    ~2 seconds
â””â”€ Suitable for:  <10K chunks

Medium Scale (10-100 PDFs):
â”œâ”€ Documents:     10-100 PDFs
â”œâ”€ Chunks:        ~10K
â”œâ”€ Index Type:    IndexIVFFlat (approximate)
â”œâ”€ Query Time:    ~500ms
â””â”€ Changes:       Add clustering to FAISS

Large Scale (100+ PDFs):
â”œâ”€ Documents:     100+ PDFs
â”œâ”€ Chunks:        ~100K+
â”œâ”€ Index Type:    IndexHNSW (graph-based)
â”œâ”€ Query Time:    ~100ms
â””â”€ Changes:       Use Pinecone/Weaviate

Enterprise Scale:
â”œâ”€ Documents:     Thousands
â”œâ”€ Chunks:        Millions
â”œâ”€ Solution:      Distributed vector DB
â”œâ”€ Technology:    Milvus, Weaviate cluster
â””â”€ Query Time:    <50ms
```

---
